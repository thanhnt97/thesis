{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "U9ksN6VYbDhR",
    "outputId": "f8bfd212-ff30-496c-fbbd-1b03b4c411b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuyển dữ liệu từ Drive sang Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/My\\ Drive/DuLieu/newnormal.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/newwheeze.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/o.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/other.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/w1.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/wheeze2.zip\n",
    "!unzip /content/drive/My\\ Drive/DuLieu/wheeze_and_crackle.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cài đặt thư viện để trích xuất đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "r-YL1fLfdiKR",
    "outputId": "731f0482-df58-4c82-a39d-acd0f1003ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/dc/cac5d1fa53146f7efac3b35655b33cb002b905fd5d1c700c651d1726b140/essentia-2.1b5-cp36-cp36m-manylinux1_x86_64.whl (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 208kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.17.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b5\n",
      "Collecting python_speech_features\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5889 sha256=8ebc916036a34e5eb299906eaf8155fce112703bbfe4bbe7d3af4079635f63a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install essentia\n",
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from shutil import copyfile\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=28)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from shutil import copyfile\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=28)\n",
    "from scipy import stats\n",
    "import python_speech_features\n",
    "from essentia.standard import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtwHbbTEbEGY"
   },
   "outputs": [],
   "source": [
    "def butter_highpass(lowcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    b, a = butter(order, low , btype='high', analog = False)\n",
    "    return b, a\n",
    "def butter_highpass_filter(data, lowcut, fs, order=5):\n",
    "    b, a = butter_highpass(lowcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dữ liệu GFCC và lưu dưới mảng Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmADVs8rdeCs"
   },
   "outputs": [],
   "source": [
    "w = Windowing(type = 'hann')\n",
    "spectrum = Spectrum()\n",
    "gfcc = GFCC(highFrequencyBound = 8000, numberCoefficients = 40, sampleRate = 16000)\n",
    "def get_gfcc(data):\n",
    "  data = butter_highpass_filter(data, 100, 16000, 9).astype(np.float32)\n",
    "  gfccs = []\n",
    "  for frame in FrameGenerator(data, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "    gfcc_bands, gfcc_coeffs = gfcc(spectrum(w(frame)))\n",
    "    gfccs.append(gfcc_coeffs)\n",
    "  return np.array(gfccs)\n",
    "def get_gfcc_all(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        X.append(get_gfcc(data))\n",
    "        Y.append(test)\n",
    "        names.append(dir + filename)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsVybbQhdvgI"
   },
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_gfcc_all(dirs,X, y,names,  labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iG82pkAPeQz8"
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"g.npy\", X)\n",
    "np.save(\"g_l.npy\", y)\n",
    "!cp g.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp g_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dữ liệu GFCC mở rộng và lưu dưới dạng numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlWzXduDe9GT"
   },
   "outputs": [],
   "source": [
    "def get_gfcc_morong(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        if idx[i] == 0:\n",
    "          for j in range(1, 15):\n",
    "            X.append(get_gfcc(np.roll(data, j * len(data)//15)))\n",
    "            Y.append(test)\n",
    "        else:\n",
    "          for j in range(1, 6):\n",
    "            X.append(get_gfcc(np.roll(data, j * len(data)//6)))\n",
    "            Y.append(test)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXe6-OYNfGio"
   },
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_gfcc_morong(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"g_a.npy\", X)\n",
    "np.save(\"g_a_l.npy\", y)\n",
    "!cp g_a.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp g_a_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dữ liệu MFCC và lưu dưới dạng Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Windowing(type = 'hann')\n",
    "spectrum = Spectrum()  # FFT() would return the complex FFT, here we just want the magnitude spectrum\n",
    "mfcc = MFCC(highFrequencyBound = 8000, sampleRate = 16000)\n",
    "gfcc = GFCC(highFrequencyBound = 8000, numberCoefficients = 40, sampleRate = 16000)\n",
    "def get_mfcc(data):\n",
    "  data = butter_highpass_filter(data, 100, 16000, 9).astype(np.float32)\n",
    "  mfccs = []\n",
    "  for frame in FrameGenerator(data, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "    mfcc_bands, mfcc_coeffs = mfcc(spectrum(w(frame)))\n",
    "    mfccs.append(mfcc_coeffs)\n",
    "  tam = np.asarray(mfccs)\n",
    "  tam1 = python_speech_features.base.delta(tam, 10)\n",
    "  tam2 = python_speech_features.base.delta(tam1, 10)\n",
    "  return np.concatenate((tam, tam1, tam2), axis = 1)\n",
    "def get_mfcc_all(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        X.append(get_mfcc(data))\n",
    "        Y.append(test)\n",
    "        names.append(dir + filename)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_mfcc_all(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"m.npy\", X)\n",
    "np.save(\"m_l.npy\", y)\n",
    "!cp m.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp m_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_morong(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        if idx[i] == 0:\n",
    "          for j in range(1, 15):\n",
    "            X.append(get_mfcc(np.roll(data, j * len(data)//15)))\n",
    "            Y.append(test)\n",
    "        else:\n",
    "          for j in range(1, 6):\n",
    "            X.append(get_mfcc(np.roll(data, j * len(data)//6)))\n",
    "            Y.append(test)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_mfcc_morong(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"m_a.npy\", X)\n",
    "np.save(\"m_a_l.npy\", y)\n",
    "!cp m_a.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp m_a_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dữ liệu MFCC GFCC và lưu dưới dạng Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Windowing(type = 'hann')\n",
    "spectrum = Spectrum()\n",
    "mfcc = MFCC(highFrequencyBound = 8000, sampleRate = 16000)\n",
    "gfcc = GFCC(highFrequencyBound = 8000, numberCoefficients = 40, sampleRate = 16000)\n",
    "def get_mfcc_gfcc(data):\n",
    "  data = butter_highpass_filter(data, 100, 16000, 9).astype(np.float32)\n",
    "  mfccs = []\n",
    "  gfccs = []\n",
    "  for frame in FrameGenerator(data, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "    mfcc_bands, mfcc_coeffs = mfcc(spectrum(w(frame)))\n",
    "    gfcc_bands, gfcc_coeffs = gfcc(spectrum(w(frame)))\n",
    "    mfccs.append(mfcc_coeffs)\n",
    "    gfccs.append(gfcc_coeffs)\n",
    "  test = np.asarray(gfccs)\n",
    "  tam = np.asarray(mfccs)\n",
    "  tam1 = python_speech_features.base.delta(tam, 10)\n",
    "  tam2 = python_speech_features.base.delta(tam1, 10)\n",
    "  return np.concatenate((test, tam, tam1, tam2), axis = 1)\n",
    "def get_mfcc_gfcc_all(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        X.append(get_mfcc_gfcc(data))\n",
    "        Y.append(test)\n",
    "        names.append(dir + filename)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_mfcc_gfcc_all(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"mg.npy\", X)\n",
    "np.save(\"mg_l.npy\", y)\n",
    "!cp mg.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp mg_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_gfcc_morong(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        if idx[i] == 0:\n",
    "          for j in range(1, 15):\n",
    "            X.append(get_mfcc_gfcc(np.roll(data, j * len(data)//15)))\n",
    "            Y.append(test)\n",
    "        else:\n",
    "          for j in range(1, 6):\n",
    "            X.append(get_mfcc_gfcc(np.roll(data, j * len(data)//6)))\n",
    "            Y.append(test)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_mfcc_gfcc_morong(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"mg_a.npy\", X)\n",
    "np.save(\"mg_a_l.npy\", y)\n",
    "!cp mg_a.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp mg_a_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dữ liệu Spectrogram và lưu dưới dạng Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(data):\n",
    "  data = butter_highpass_filter(data, 100, 16000, 9).astype(np.float32)\n",
    "  spec = librosa.stft(data, n_fft = 1024, hop_length = 512)\n",
    "  return librosa.power_to_db(np.abs(spec) ** 2)\n",
    "def get_spectrogram_all(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        X.append(get_spectrogram(data))\n",
    "        Y.append(test)\n",
    "        names.append(dir + filename)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_spectrogram_all(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"s.npy\", X)\n",
    "np.save(\"s_l.npy\", y)\n",
    "!cp s.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp s_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_morong(dirs, X, Y, names, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        if idx[i] == 0:\n",
    "          for j in range(1, 15):\n",
    "            X.append(get_spectrogram(np.roll(data, j * len(data)//15)))\n",
    "            Y.append(test)\n",
    "        else:\n",
    "          for j in range(1, 6):\n",
    "            X.append(get_spectrogram(np.roll(data, j * len(data)//6)))\n",
    "            Y.append(test)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\", \"/content/newwheeze\", \"/content/newnormal\"]\n",
    "labels = [0, 1, 0, 0, 1, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "names = []\n",
    "get_spectrogram_morong(dirs,X, y,names,  labels )\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(\"s_a.npy\", X)\n",
    "np.save(\"s_a_l.npy\", y)\n",
    "!cp s_a.npy /content/drive/My\\ Drive/DuLieu/filter_feature\n",
    "!cp s_a_l.npy /content/drive/My\\ Drive/DuLieu/filter_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GFCC_case134_ptit.nickdangki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
