{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "tYvuKU-prOvo",
    "outputId": "f7e90a16-ae32-4796-c1d5-ecfddfd23a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tải dữ liệu từ Drive vào Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zl2BqUTxrPOL"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/DuLieu/filter_feature/m_a.npy .\n",
    "!cp /content/drive/My\\ Drive/DuLieu/filter_feature/m_a_l.npy ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HqtCplt2sYe4",
    "outputId": "947e5366-dc0f-4110-ab26-7269e8469504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from shutil import copyfile\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=28)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbShrtHgselq"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(64, return_sequences=True))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dense(1, activation = \"sigmoid\"))\n",
    "  model.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adam(lr = 0.0005), metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tr3Yo8n_P42_"
   },
   "outputs": [],
   "source": [
    "class LogConfusionMatrix(keras.callbacks.Callback):\n",
    "  def __init__(self, names):\n",
    "    self.names = names\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.bestacc = 0.0\n",
    "    self.bestcf = None\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if logs[\"val_acc\"] > self.bestacc:\n",
    "      self.bestacc = logs[\"val_acc\"] \n",
    "      y_pred = self.model.predict(self.validation_data[0])\n",
    "      y_pred = [1 * (x[0]>=0.5) for x in y_pred]\n",
    "      self.bestcf = confusion_matrix(self.validation_data[1], y_pred)\n",
    "  def on_train_end(self, logs = {}):\n",
    "    f = open(self.names, \"a\")\n",
    "    f.write(\"Best val_acc: \" + str(self.bestacc))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Best cf: \\n\" + str(self.bestcf))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs3xjtEIsiqa"
   },
   "outputs": [],
   "source": [
    "def train_case_2(X_aug, y_aug, filename, epochs = 40):\n",
    "  i = 1\n",
    "  for train_index, test_index in kf.split(X_aug):\n",
    "    print(\"Cross Valid: \" + str(i))\n",
    "    f = open(filename, \"a\")\n",
    "    f.write(\"Cross Valid: \" + str(i))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    logcf = LogConfusionMatrix(filename)\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.008, patience=9, verbose=1, mode='auto')\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = \"loss\",patience = 3, factor = 0.8, min_lr = 0.0001, verbose = 1)\n",
    "    model = create_model()\n",
    "    mean = np.mean(X_aug[train_index], axis = 0)\n",
    "    std = np.std(X_aug[train_index], axis = 0)\n",
    "    X_train = (X_aug[train_index] - mean) / std\n",
    "    y_train = y_aug[train_index]\n",
    "    X_test = (X_aug[test_index] - mean) / std\n",
    "    y_test = y_aug[test_index]\n",
    "    model.fit(X_train, y_train, epochs = epochs, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks = [es, logcf, reduce_lr])\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    gc.collect()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEuCvgO_sk37"
   },
   "outputs": [],
   "source": [
    "X = np.load(\"m_a.npy\")\n",
    "y = np.load(\"m_a_l.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BymbmKCAsqYl",
    "outputId": "5d0e349d-e695-4405-f102-24dc9b307515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Valid: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30968/30968 [==============================] - 110s 4ms/step - loss: 0.3316 - acc: 0.8586 - val_loss: 0.2202 - val_acc: 0.9169\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.1647 - acc: 0.9402 - val_loss: 0.1372 - val_acc: 0.9490\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.1068 - acc: 0.9633 - val_loss: 0.1026 - val_acc: 0.9656\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0730 - acc: 0.9762 - val_loss: 0.0754 - val_acc: 0.9764\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0523 - acc: 0.9833 - val_loss: 0.0658 - val_acc: 0.9784\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0397 - acc: 0.9867 - val_loss: 0.0662 - val_acc: 0.9762\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0395 - acc: 0.9865 - val_loss: 0.0391 - val_acc: 0.9855\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0415 - val_acc: 0.9863\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0342 - val_acc: 0.9873\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 109s 4ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0415 - val_acc: 0.9853\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 108s 3ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0298 - val_acc: 0.9904\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0232 - val_acc: 0.9929\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 108s 3ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0229 - val_acc: 0.9924\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0281 - val_acc: 0.9890\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0166 - val_acc: 0.9951\n",
      "Epoch 17/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0156 - val_acc: 0.9952\n",
      "Epoch 18/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0111 - acc: 0.9962 - val_loss: 0.0191 - val_acc: 0.9944\n",
      "Epoch 19/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0265 - acc: 0.9923 - val_loss: 0.0392 - val_acc: 0.9877\n",
      "Epoch 20/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0184 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 21/40\n",
      "30968/30968 [==============================] - 109s 4ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0298 - val_acc: 0.9906\n",
      "Epoch 22/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0114 - val_acc: 0.9960\n",
      "Epoch 23/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0186 - val_acc: 0.9938\n",
      "Epoch 24/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0184 - val_acc: 0.9933\n",
      "Epoch 25/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0216 - val_acc: 0.9943\n",
      "Epoch 00025: early stopping\n",
      "Cross Valid: 2\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.3330 - acc: 0.8579 - val_loss: 0.1901 - val_acc: 0.9281\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.1543 - acc: 0.9446 - val_loss: 0.1094 - val_acc: 0.9632\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0999 - acc: 0.9672 - val_loss: 0.0939 - val_acc: 0.9680\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0682 - acc: 0.9778 - val_loss: 0.0710 - val_acc: 0.9778\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0477 - acc: 0.9844 - val_loss: 0.0606 - val_acc: 0.9815\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0411 - acc: 0.9862 - val_loss: 0.0459 - val_acc: 0.9855\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0543 - val_acc: 0.9837\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0228 - acc: 0.9927 - val_loss: 0.0452 - val_acc: 0.9853\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0236 - acc: 0.9924 - val_loss: 0.0479 - val_acc: 0.9862\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0404 - val_acc: 0.9867\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.0427 - val_acc: 0.9866\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0333 - val_acc: 0.9901\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0463 - val_acc: 0.9853\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0310 - val_acc: 0.9902\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0269 - val_acc: 0.9925\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0282 - val_acc: 0.9925\n",
      "Epoch 17/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0336 - val_acc: 0.9886\n",
      "Epoch 18/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0338 - val_acc: 0.9901\n",
      "Epoch 00018: early stopping\n",
      "Cross Valid: 3\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 111s 4ms/step - loss: 0.3261 - acc: 0.8616 - val_loss: 0.2101 - val_acc: 0.9247\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.1642 - acc: 0.9437 - val_loss: 0.1384 - val_acc: 0.9487\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.1052 - acc: 0.9639 - val_loss: 0.0856 - val_acc: 0.9715\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0686 - acc: 0.9781 - val_loss: 0.0708 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0530 - acc: 0.9833 - val_loss: 0.0640 - val_acc: 0.9777\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0383 - acc: 0.9884 - val_loss: 0.0437 - val_acc: 0.9851\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0496 - acc: 0.9823 - val_loss: 0.1009 - val_acc: 0.9712\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0285 - acc: 0.9902 - val_loss: 0.0427 - val_acc: 0.9882\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0166 - acc: 0.9942 - val_loss: 0.0306 - val_acc: 0.9903\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0505 - val_acc: 0.9846\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0359 - val_acc: 0.9884\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.0325 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0260 - val_acc: 0.9919\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0306 - val_acc: 0.9910\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0321 - val_acc: 0.9894\n",
      "Epoch 00015: early stopping\n",
      "Cross Valid: 4\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 108s 4ms/step - loss: 0.3412 - acc: 0.8546 - val_loss: 0.2098 - val_acc: 0.9273\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.1638 - acc: 0.9423 - val_loss: 0.1267 - val_acc: 0.9552\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.1102 - acc: 0.9618 - val_loss: 0.0942 - val_acc: 0.9684\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0719 - acc: 0.9771 - val_loss: 0.0817 - val_acc: 0.9718\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0506 - acc: 0.9842 - val_loss: 0.0686 - val_acc: 0.9742\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 108s 3ms/step - loss: 0.0474 - acc: 0.9857 - val_loss: 0.0550 - val_acc: 0.9818\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0345 - acc: 0.9895 - val_loss: 0.0570 - val_acc: 0.9844\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0315 - acc: 0.9905 - val_loss: 0.0559 - val_acc: 0.9808\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0385 - val_acc: 0.9879\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 108s 3ms/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0328 - val_acc: 0.9888\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0356 - val_acc: 0.9879\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0276 - val_acc: 0.9912\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0341 - val_acc: 0.9913\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0528 - val_acc: 0.9846\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0211 - acc: 0.9928 - val_loss: 0.0321 - val_acc: 0.9895\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0309 - val_acc: 0.9908\n",
      "Epoch 17/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0346 - val_acc: 0.9901\n",
      "Epoch 18/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0253 - val_acc: 0.9929\n",
      "Epoch 19/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0296 - val_acc: 0.9913\n",
      "Epoch 20/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0216 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 21/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 00021: early stopping\n",
      "Cross Valid: 5\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 111s 4ms/step - loss: 0.3327 - acc: 0.8578 - val_loss: 0.2043 - val_acc: 0.9282\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.1688 - acc: 0.9397 - val_loss: 0.1201 - val_acc: 0.9607\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.1035 - acc: 0.9644 - val_loss: 0.0933 - val_acc: 0.9709\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0695 - acc: 0.9777 - val_loss: 0.0612 - val_acc: 0.9796\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0489 - acc: 0.9833 - val_loss: 0.0612 - val_acc: 0.9791\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0373 - acc: 0.9880 - val_loss: 0.0373 - val_acc: 0.9863\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 108s 3ms/step - loss: 0.0290 - acc: 0.9896 - val_loss: 0.0304 - val_acc: 0.9879\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0489 - val_acc: 0.9846\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0186 - acc: 0.9933 - val_loss: 0.0453 - val_acc: 0.9842\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 107s 3ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0335 - val_acc: 0.9881\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.0339 - val_acc: 0.9881\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0239 - val_acc: 0.9930\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9901\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0252 - val_acc: 0.9919\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 109s 4ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0452 - val_acc: 0.9853\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 106s 3ms/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0331 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_case_2(X, y, \"mfcc_case_2.txt\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YP4J0iANsuyG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MFCC_case2_zzz.testthoi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
