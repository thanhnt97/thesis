{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "tYvuKU-prOvo",
    "outputId": "0a5ecd86-dbf5-4ad3-ccf3-f69c64d5c91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zl2BqUTxrPOL"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/DuLieu/filter_feature/g_a.npy .\n",
    "!cp /content/drive/My\\ Drive/DuLieu/filter_feature/g_a_l.npy ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HqtCplt2sYe4",
    "outputId": "9b9dbd36-5a31-44de-8f44-71827f594cca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from shutil import copyfile\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=28)\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbShrtHgselq"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(64, return_sequences=True))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dense(1, activation = \"sigmoid\"))\n",
    "  model.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adam(lr = 0.0005), metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAPu7LRCQfM4"
   },
   "outputs": [],
   "source": [
    "class LogConfusionMatrix(keras.callbacks.Callback):\n",
    "  def __init__(self, names):\n",
    "    self.names = names\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.bestacc = 0.0\n",
    "    self.bestcf = None\n",
    "  def on_epoch_end(self, epoch, logs = {}):\n",
    "    if logs[\"val_acc\"] > self.bestacc:\n",
    "      self.bestacc = logs[\"val_acc\"] \n",
    "      y_pred = self.model.predict(self.validation_data[0])\n",
    "      y_pred = [1 * (x[0]>=0.5) for x in y_pred]\n",
    "      self.bestcf = confusion_matrix(self.validation_data[1], y_pred)\n",
    "  def on_train_end(self, logs = {}):\n",
    "    f = open(self.names, \"a\")\n",
    "    f.write(\"Best val_acc: \" + str(self.bestacc))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Best cf: \\n\" + str(self.bestcf))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs3xjtEIsiqa"
   },
   "outputs": [],
   "source": [
    "def train_case_2(X_aug, y_aug, filename, epochs = 40):\n",
    "  i = 1\n",
    "  for train_index, test_index in kf.split(X_aug):\n",
    "    print(\"Cross Valid: \" + str(i))\n",
    "    f = open(filename, \"a\")\n",
    "    f.write(\"Cross Valid: \" + str(i))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    logcf = LogConfusionMatrix(filename)\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.008, patience=9, verbose=1, mode='auto')\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = \"loss\",patience = 3, factor = 0.8, min_lr = 0.0001, verbose = 1)\n",
    "    model = create_model()\n",
    "    mean = np.mean(X_aug[train_index], axis = 0)\n",
    "    std = np.std(X_aug[train_index], axis = 0)\n",
    "    X_train = (X_aug[train_index] - mean) / std\n",
    "    y_train = y_aug[train_index]\n",
    "    X_test = (X_aug[test_index] - mean) / std\n",
    "    y_test = y_aug[test_index]\n",
    "    model.fit(X_train, y_train, epochs = epochs, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks = [es, logcf, reduce_lr])\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    gc.collect()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEuCvgO_sk37"
   },
   "outputs": [],
   "source": [
    "X = np.load(\"g_a.npy\")\n",
    "y = np.load(\"g_a_l.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BymbmKCAsqYl",
    "outputId": "a0ba42a0-aa2f-44d6-dfc6-0c5b3cbfab51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Valid: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "30968/30968 [==============================] - 105s 3ms/step - loss: 0.2960 - acc: 0.8745 - val_loss: 0.2003 - val_acc: 0.9328\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 102s 3ms/step - loss: 0.1421 - acc: 0.9466 - val_loss: 0.1198 - val_acc: 0.9582\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0933 - acc: 0.9683 - val_loss: 0.0727 - val_acc: 0.9771\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0665 - acc: 0.9774 - val_loss: 0.0567 - val_acc: 0.9824\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0481 - acc: 0.9849 - val_loss: 0.0397 - val_acc: 0.9870\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0324 - acc: 0.9907 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.0227 - val_acc: 0.9930\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0169 - acc: 0.9956 - val_loss: 0.0137 - val_acc: 0.9959\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0338 - acc: 0.9906 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.0249 - val_acc: 0.9920\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0150 - val_acc: 0.9950\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 97s 3ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0160 - val_acc: 0.9957\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0366 - val_acc: 0.9898\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0079 - val_acc: 0.9977\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0220 - val_acc: 0.9910\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0081 - acc: 0.9971 - val_loss: 0.0082 - val_acc: 0.9977\n",
      "Epoch 17/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0086 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 00017: early stopping\n",
      "Cross Valid: 2\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.3093 - acc: 0.8705 - val_loss: 0.1818 - val_acc: 0.9304\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.1487 - acc: 0.9488 - val_loss: 0.1171 - val_acc: 0.9589\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0929 - acc: 0.9694 - val_loss: 0.0717 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0629 - acc: 0.9778 - val_loss: 0.0619 - val_acc: 0.9799\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0514 - acc: 0.9818 - val_loss: 0.0442 - val_acc: 0.9840\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0234 - acc: 0.9922 - val_loss: 0.0535 - val_acc: 0.9828\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0295 - acc: 0.9911 - val_loss: 0.0242 - val_acc: 0.9923\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0215 - val_acc: 0.9913\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0112 - val_acc: 0.9965\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0215 - acc: 0.9942 - val_loss: 0.0146 - val_acc: 0.9965\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0647 - val_acc: 0.9799\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0143 - val_acc: 0.9963\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0064 - val_acc: 0.9983\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0122 - val_acc: 0.9964\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0125 - val_acc: 0.9964\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0089 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 00016: early stopping\n",
      "Cross Valid: 3\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.3298 - acc: 0.8619 - val_loss: 0.2115 - val_acc: 0.9265\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.1637 - acc: 0.9435 - val_loss: 0.1166 - val_acc: 0.9588\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0923 - acc: 0.9706 - val_loss: 0.0763 - val_acc: 0.9733\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0635 - acc: 0.9796 - val_loss: 0.0568 - val_acc: 0.9796\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0443 - acc: 0.9848 - val_loss: 0.0754 - val_acc: 0.9755\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 97s 3ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0180 - val_acc: 0.9944\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 97s 3ms/step - loss: 0.0248 - acc: 0.9928 - val_loss: 0.0404 - val_acc: 0.9854\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0147 - val_acc: 0.9952\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 95s 3ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0083 - val_acc: 0.9975\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0169 - acc: 0.9955 - val_loss: 0.0123 - val_acc: 0.9964\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 97s 3ms/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0126 - val_acc: 0.9955\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0096 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0066 - val_acc: 0.9975\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0050 - val_acc: 0.9985\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 97s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0047 - val_acc: 0.9987\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.0106 - val_acc: 0.9961\n",
      "Epoch 00016: early stopping\n",
      "Cross Valid: 4\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 104s 3ms/step - loss: 0.3168 - acc: 0.8671 - val_loss: 0.1840 - val_acc: 0.9323\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.1978 - acc: 0.9238 - val_loss: 0.1495 - val_acc: 0.9438\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.1642 - acc: 0.9370 - val_loss: 0.1248 - val_acc: 0.9562\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.1708 - acc: 0.9310 - val_loss: 0.1990 - val_acc: 0.9123\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.1136 - acc: 0.9604 - val_loss: 0.0925 - val_acc: 0.9727\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0726 - acc: 0.9778 - val_loss: 0.0747 - val_acc: 0.9783\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0510 - acc: 0.9856 - val_loss: 0.0572 - val_acc: 0.9839\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0476 - acc: 0.9862 - val_loss: 0.0655 - val_acc: 0.9799\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0353 - acc: 0.9897 - val_loss: 0.0427 - val_acc: 0.9872\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0290 - acc: 0.9919 - val_loss: 0.0434 - val_acc: 0.9855\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0369 - acc: 0.9890 - val_loss: 0.0319 - val_acc: 0.9907\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0268 - acc: 0.9930 - val_loss: 0.0244 - val_acc: 0.9921\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0198 - acc: 0.9947 - val_loss: 0.0280 - val_acc: 0.9917\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 98s 3ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.0289 - val_acc: 0.9907\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.0285 - val_acc: 0.9919\n",
      "Epoch 16/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0296 - acc: 0.9897 - val_loss: 0.0322 - val_acc: 0.9861\n",
      "Epoch 17/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0112 - val_acc: 0.9965\n",
      "Epoch 18/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0279 - val_acc: 0.9924\n",
      "Epoch 19/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0279 - val_acc: 0.9951\n",
      "Epoch 20/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0223 - acc: 0.9942 - val_loss: 0.0113 - val_acc: 0.9970\n",
      "Epoch 21/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0064 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 22/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0077 - val_acc: 0.9979\n",
      "Epoch 23/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0426 - val_acc: 0.9915\n",
      "Epoch 00023: early stopping\n",
      "Cross Valid: 5\n",
      "Train on 30968 samples, validate on 7742 samples\n",
      "Epoch 1/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.3099 - acc: 0.8689 - val_loss: 0.1639 - val_acc: 0.9417\n",
      "Epoch 2/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.1432 - acc: 0.9487 - val_loss: 0.1012 - val_acc: 0.9667\n",
      "Epoch 3/40\n",
      "30968/30968 [==============================] - 99s 3ms/step - loss: 0.0903 - acc: 0.9695 - val_loss: 0.0709 - val_acc: 0.9782\n",
      "Epoch 4/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0599 - val_acc: 0.9824\n",
      "Epoch 5/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0476 - acc: 0.9856 - val_loss: 0.0508 - val_acc: 0.9839\n",
      "Epoch 6/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.0422 - acc: 0.9877 - val_loss: 0.0303 - val_acc: 0.9926\n",
      "Epoch 7/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0274 - acc: 0.9927 - val_loss: 0.0230 - val_acc: 0.9941\n",
      "Epoch 8/40\n",
      "30968/30968 [==============================] - 101s 3ms/step - loss: 0.0208 - acc: 0.9948 - val_loss: 0.0465 - val_acc: 0.9875\n",
      "Epoch 9/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0464 - acc: 0.9864 - val_loss: 0.0259 - val_acc: 0.9928\n",
      "Epoch 10/40\n",
      "30968/30968 [==============================] - 100s 3ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.0193 - val_acc: 0.9935\n",
      "Epoch 11/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.0140 - val_acc: 0.9965\n",
      "Epoch 12/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0097 - val_acc: 0.9970\n",
      "Epoch 13/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.0178 - acc: 0.9959 - val_loss: 0.0157 - val_acc: 0.9956\n",
      "Epoch 14/40\n",
      "30968/30968 [==============================] - 103s 3ms/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0126 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 15/40\n",
      "30968/30968 [==============================] - 102s 3ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_case_2(X, y, \"gfcc_case_2.txt\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YP4J0iANsuyG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gfcc_case2_zzz.testthoi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
